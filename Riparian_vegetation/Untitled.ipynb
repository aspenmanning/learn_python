{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "import time\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import show\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "from rasterio.mask import mask as rmask\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from skimage.segmentation import slic, felzenszwalb, watershed\n",
    "from skimage.future import graph\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters.rank import modal\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn import svm\n",
    "from collections import OrderedDict\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from rasterstats import zonal_stats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyzing Riparian Vegetation with GEOBIA\n",
    "## by Aspen Manning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "- Ephemeral streams\n",
    "- Riparian vegetation\n",
    "- Connectivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![riparian vegetation](ChevelonRiparianVegetation.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Study Area\n",
    "Chevelon Fork, Northern Arizona\n",
    "- Intermittent with ephemeral tributaries\n",
    "- Tributary to Little Colorado River\n",
    "- Landscape changes from headwaters to mouth\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Headwaters vegetation](ChevelonMtnUpland.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Headwaters riparian vegetation](ChevelonPines.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Mouth vegetation](ChevelonDryUpland.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Desert Riparian vegetation](ChevelonTamarix.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal for this project\n",
    "![NDVI Map](NDVI.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Map 1](Mainmap.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Segmentation and Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from data_preparation.py as dp\n",
    "\n",
    "def rasterize(gdf, value_column, shape, transform):\n",
    "    \"\"\"\n",
    "    Rasterizes a GeoDataFrame\n",
    "    \n",
    "    Rasterizes a GeoDataFrame where the value_column becomes the pixel id.\n",
    "    \"\"\"\n",
    "    p = _geometry_value_pairs(gdf, value_column)\n",
    "    image = features.rasterize(p, out_shape=shape, transform=transform)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from data_preparation.py as dp\n",
    "\n",
    "def vectorize(src=None, image=None, transform=None, crs=None):\n",
    "    \"\"\"\n",
    "    Raster-to-Vector conversion.\n",
    "    \n",
    "    Performs a raster-to-vector conversion of a classified image. \n",
    "    \"\"\"\n",
    "    if src is not None:\n",
    "        img = src.read(1, masked=True)\n",
    "        transform = src.transform\n",
    "        crs = src.crs.to_proj4()\n",
    "    else:\n",
    "        img = image[0].astype(np.int32)\n",
    "        \n",
    "    shps = features.shapes(img, transform=transform)\n",
    "    records = []\n",
    "\n",
    "    for id, shp in enumerate(shps):\n",
    "        if shp[1] != 0:\n",
    "            item = {'geometry': shp[0], 'id': id+1, 'properties': \n",
    "                    OrderedDict([('dn', np.int(shp[1]))]),\n",
    "                    'type': 'Feature'}\n",
    "            records.append(item)\n",
    "\n",
    "    vec = GeoDataFrame.from_features(records)\n",
    "    vec.crs = crs\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from data_preparation.py as dp\n",
    "\n",
    "def add_zonal_properties(src=None, bands=[1,2,3], image=None, transform=None,\n",
    "                         band_names=['red','green','blue'], stats=['mean'],\n",
    "                         gdf=None):\n",
    "    \"\"\"\n",
    "    Adds zonal properties to a GeoDataFrame.\n",
    "    \n",
    "    Adds zonal properties to a GeoDataFrame, where the statistics 'stats' are\n",
    "    calculated for all pixels within the geographic objects boundaries.\n",
    "     \"\"\"\n",
    "    if src is not None:\n",
    "        image = src.read(bands, masked=True)\n",
    "        transform = src.transform\n",
    "\n",
    "    if len(image) != len(band_names): \n",
    "        print(\"The number of bands must equal the number of bands_names.\")\n",
    "        return None\n",
    "\n",
    "    for band, name in enumerate(band_names):\n",
    "        raster_stats = zonal_stats(gdf, image[band], stats=stats, \n",
    "                                   affine=transform)\n",
    "        \n",
    "        fields = [[] for i in range(len(stats))]\n",
    "        labels = []\n",
    "        \n",
    "        for i, rs in enumerate(raster_stats):\n",
    "            for j, r in enumerate(rs):\n",
    "                if i == 0:\n",
    "                    labels.append(r)\n",
    "                fields[j].append(rs[r])\n",
    "        \n",
    "        for i, l in enumerate(labels):\n",
    "            gdf.insert(len(gdf.columns)-1, name + \"_\" + l, fields[i])\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_prop(props, label):\n",
    "    for p in props:\n",
    "        if p.label == label:\n",
    "            return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from data_preparation.py as dp\n",
    "\n",
    "def add_shape_properties(classified_image, gdf, attributes=['area', 'perimeter']):\n",
    "    \"\"\"\n",
    "    Add raster properties as vector fields.\n",
    "    \"\"\"\n",
    "    clim = classified_image[0, :, :]\n",
    "    props = regionprops(clim)\n",
    "    \n",
    "    attributes = {s: [] for s in attributes}\n",
    "\n",
    "    for row in gdf.itertuples():\n",
    "        rid = getattr(row, 'dn')\n",
    "        \n",
    "        p = get_prop(props, rid)\n",
    "        if p is not None:\n",
    "            for a in attributes:\n",
    "                attributes[a].append(getattr(p, a))\n",
    "\n",
    "    try:\n",
    "        for a in attributes:\n",
    "            if (a == 'area'):\n",
    "                gdf.insert(len(gdf.columns)-1, a, gdf.geometry.area)\n",
    "            elif (a == 'perimeter'):\n",
    "                gdf.insert(len(gdf.columns)-1, a, gdf.geometry.length)\n",
    "            else:\n",
    "                gdf.insert(len(gdf.columns)-1, a, attributes[a])\n",
    "    except:\n",
    "        print(\"The geometry is bad for this gdf.\")\n",
    "        print(gdf.columns)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from data_preparation.py as dp\n",
    "\n",
    "def bsq_to_bip(image):\n",
    "    # no error checking yet...\n",
    "    return  image.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "def bip_to_bsq(image):\n",
    "    # no error checking yet...\n",
    "    return  image.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def sobel_edge_detect(src=None, band=1, image=None, mask=None):\n",
    "    \"\"\"\n",
    "    Performs a Sobel edge detection.\n",
    "\n",
    "    Performs a Sobel edge detection on a 2D image.\n",
    "    \"\"\"\n",
    "    if src is not None:\n",
    "        image = src.read(band, masked=True)\n",
    "        mask = src.read_masks(1)\n",
    "#         mask[mask > 0] = 1\n",
    "    else:\n",
    "        image = image\n",
    "#         mask[mask > 255] = 1\n",
    "        \n",
    "    edges = sobel(image)\n",
    "    return bip_to_bsq(edges[:, :, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from data_preparation.py as dp\n",
    "\n",
    "def segmentation(model=None, params=None, src=None, bands=[1,2,3], image=None,\n",
    "                 mask=None, modal_radius=None, sieve_size=250):\n",
    "    \"\"\"\n",
    "    Segment the image.\n",
    "\n",
    "    Segment the image using an algorithm from sklearn.segmentation.\n",
    "     \"\"\"\n",
    "    if src is not None:\n",
    "        img = bsq_to_bip(src.read(bands, masked=True))\n",
    "        mask = src.read_masks(1)\n",
    "        mask[mask > 0] = 1\n",
    "    else:\n",
    "        img = bsq_to_bip(image)\n",
    "\n",
    "    output = model(img, **params).astype('int32')\n",
    "\n",
    "    while np.ndarray.min(output) < 1:\n",
    "        output += 1\n",
    "\n",
    "    if modal_radius != None:\n",
    "        output = modal(output.astype('int16'), selem=disk(modal_radius))\n",
    "\n",
    "    output = features.sieve(output, sieve_size)\n",
    "    output = label(output, connectivity=1)\n",
    "    \n",
    "    output = bip_to_bsq(output[:, :, np.newaxis])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# from skimage import data, io, segmentation, color\n",
    "# from skimage.future import graph\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "def _weight_mean_color(graph, src, dst, n):\n",
    "    diff = graph.node[dst]['mean color'] - graph.node[n]['mean color']\n",
    "    diff = np.linalg.norm(diff)\n",
    "    return {'weight': diff}\n",
    "\n",
    "\n",
    "def merge_mean_color(graph, src, dst):\n",
    "    graph.node[dst]['total color'] += graph.node[src]['total color']\n",
    "    graph.node[dst]['pixel count'] += graph.node[src]['pixel count']\n",
    "    graph.node[dst]['mean color'] = (graph.node[dst]['total color'] /\n",
    "                                     graph.node[dst]['pixel count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with rasterio.open(\"Chevelon.tif\") as src:\n",
    "    felz_params = {\n",
    "        'scale': 0.01,\n",
    "        'sigma': 0.5,\n",
    "        'min_size': 10\n",
    "    }\n",
    "\n",
    "    ## This makes very small segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "shapes = gpd.read_file(\"Chevelon.shp\")\n",
    "    out_image, out_transform = rmask(src, shapes.geometry, crop=True)\n",
    "    image = out_image[0:3, :, :]\n",
    "    rout = segmentation(model=felzenszwalb, params=felz_params, image=image)\n",
    "    vout = vectorize(image=rout, transform=out_transform,\n",
    "                     crs=src.crs.to_proj4())\n",
    "\n",
    "    vout.to_file(\"ChevelonCkWS.gpkg\", layer=\"initialSegments\", driver=\"GPKG\")\n",
    "    orig = bsq_to_bip(image)\n",
    "    labels = (bsq_to_bip(rout))[:, :, 0]\n",
    "\n",
    "    rag = graph.rag_mean_color(orig, labels, mode='similarity', sigma=0.2)\n",
    "    rout = graph.merge_hierarchical(labels, rag, thresh=50, rag_copy=False,\n",
    "                             in_place_merge=True,\n",
    "                             merge_func=merge_mean_color,\n",
    "                             weight_func=_weight_mean_color)\n",
    "    rout = bip_to_bsq(rout[:, :, np.newaxis])\n",
    "    vout = vectorize(image=rout, transform=out_transform,\n",
    "                    crs=src.crs.to_proj4())\n",
    "    vout = add_zonal_properties(image=out_image, transform=out_transform, \n",
    "                                bands=[1, 2, 3, 4], band_names=['blue', 'green', 'red', 'nir', ],\n",
    "                                stats=['mean','min','max','std'], gdf=vout)\n",
    "    vout = add_shape_properties(rout, vout, ['area', 'perimeter',\n",
    "                                             'eccentricity', \n",
    "                                             'equivalent_diameter',\n",
    "                                             'major_axis_length',\n",
    "                                             'minor_axis_length',\n",
    "                                             'orientation'])\n",
    "     edges = sobel_edge_detect(src, band=1)\n",
    "    vout = add_zonal_properties(image=edges, band_names=['sobel'],\n",
    "                                stats=['mean','min','max','std'],\n",
    "                                transform=out_transform, gdf=vout)\n",
    "\n",
    "    vout.to_file(\"ChevelonCkWS.gpkg\", layer=\"ready2classify\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train(X, Y):\n",
    "    \"\"\"\n",
    "    Train classification algorithm.\n",
    "    \n",
    "    Train the Support Vector Machine classification algorithm using the\n",
    "    specified fields. \n",
    "    \"\"\"\n",
    "    clf = svm.SVC()\n",
    "        \n",
    "    # specify parameters and distributions to sample from\n",
    "    param_dist = {'C': expon(scale=100),\n",
    "                  'gamma': expon(scale=.1),\n",
    "                  'kernel': ['rbf'],\n",
    "                  'class_weight':['balanced', None]}\n",
    "\n",
    "    # run randomized search\n",
    "    n_iter_search = 20\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "    random_search.fit(X, Y) # this may take time...\n",
    "    \n",
    "    return random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    \"\"\"\n",
    "    Classify segments using a trained SVM model\n",
    "\n",
    "    Classify image segments using the trained Support Vector Machine model. \n",
    "    \"\"\"\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for_training = gpd.read_file(\"ClassifiedChevelon.gpkg\")\n",
    "for_training.head\n",
    "big_train = for_training[~np.isnan(for_training[\"Class\"])]\n",
    "big_train.head\n",
    "big_train.columns.values\n",
    "labels = big_train['Class']\n",
    "classes = big_train[['red_mean', 'green_mean', \"blue_mean\", \"nir_mean\", \"eccentricity\", \"orientation\", \"sobel_max\", \"ndvi\"]]\n",
    "model = train(classes, labels)\n",
    "to_predict = for_training[['red_mean', 'green_mean', \"blue_mean\", \"nir_mean\", \"eccentricity\", \"orientation\", \"sobel_max\", \"ndvi\"]]\n",
    "output = predict(model, to_predict.values)\n",
    "for_training['classified'] = output\n",
    "for_training.to_file(\"chev2_output.gpkg\", layer = \"predictions\", driver = \"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "- 36,802 segments\n",
    "- 3 classes: riparian vegetation, upland vegetation, bare soil/sparse vegetation\n",
    "- 831 segments of riparian vegetation (mean NDVI = 0.47) \n",
    "- 3,630 segments of bare soil/sparse vegetation (mean NDVI = 0.20)\n",
    "- 32,341 segments of upland vegetation (mean NDVI = 0.29) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Classified Map](Classes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy\n",
    "- Checked against the NDVI map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Accuracy map](Accuracy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "- Classification would need tweaked to be useful \n",
    "- Segmentation is difficult when identifying small objects in a large image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
